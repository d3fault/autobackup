every 1 second we use a random number mod N (where N is number of nodes in cluster) to decide if we're going to check the state of the db. if we decide to check, we first get the campaign doc and then see if the campaign doc's "last purchased slot" + 1 exists, indicating a Wt/Driver may have purchased a slot and then failed to finish the rest of the paperwork. We then wait 100ms to give the Wt/Driver time to finish. If after 100ms the campaign doc (re-gotten) still doesn't reflect the slot+1 that we detected exists, we do the paperwork for him and update the campaign doc reflecting this... bringing the state of the sytem back to normal. We are careful to CAS-swap at each step, but we accept failures and move onto the next stage of recovery (our brethren (different instances of us on different machines)) might have selected themselves to do the recovery tasks as well.

Most notably, the CAS for the initial campaign doc (more specifically, the 2nd one after 100ms extra time) _MUST_ be used in the final CAS-swap (accepting fail) to update the campaign at the very end of the recovery.