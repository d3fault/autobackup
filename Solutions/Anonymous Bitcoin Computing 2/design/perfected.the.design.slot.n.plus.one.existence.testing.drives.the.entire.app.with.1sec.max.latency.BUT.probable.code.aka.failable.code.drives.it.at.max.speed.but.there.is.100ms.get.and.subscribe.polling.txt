Get and subscribe via lazy polling with 100ms "max stale time" (if <= 100ms, give em cache) for the "campaign doc". Get and subscribing the campaign doc also subscribes the wt node (same "class" or "scope" that does the get and subscribe > 100ms check/fetch/cache-hit-return) to the associated "slotFillerN+1" in a custom-hack-yet-fucking-awesome "rand() % 10 == 0 ? checkToSeeIfSlotFillerN+1existsAsA_WORST_CASE_SCENARIO_CONSTANT_RECOVERY_MODE_AND_WHEN_ENGAGED_DOES_CAS_SWAP_UPDATING_CAMPAIGN_DOC(and user doc (unlock) if need be (incl debiting), and transaction doc which must be LCB_ADD'd (using specific slot name (incidentally a key!) cleverly in key choice) before the user-account is unlocked which i think mitigates that race conditon from login-recovery i was thinking of doing (and now know better)). So basically if we checktoSeIfSlotFillerN is there, we double check campaign doc to make sure we didn't just 'get lucky' (will happen quite often), THEN we simply do nothing for ANOTHER 100ms to give our neighbors who we could have 'gotten lucky' and beaten to getting the campaign doc before they could update it some more time (100ms is ample (yet low to human)), then we verify in this exact order: the transaction exists. whether or not it exists we then go to the user-account (with balance) and make sure that the "slotAboutToBuy" wasn't the one we are in the process of error recovering from. It could be empty which means the account is unlocked and all that means is that we need to make the transaction document (which may have even been added by the time we get around to it, so we are ok with our LCB_ADD failing with key exists). If the transaction document doens't exist and the user account is still locked to the slot we are attempting recovery from, then we try to LCB_ADD it just like before, but then regardless of whether we succeed with the LCB_ADD at this point we also try to unlock the user-account (this is actually overkill at this point (if we failed to get the LCB_ADD just mentioned), but it is safe to do so long as we CAS-swap-unlock it (and accept first failure (because any unlocking by neighbors will have finished the same transaction (and maybe started another, which is irrelevant) because there would be ~2 nodes trying to do the user-account-unlocked (one acting in '1-sec-max-recovery-mode-false-positives-ok' mode (the description of everything so far), as the false positive himself)). Of course if the user-account is locked to another slot and the transaction isn't made, we know the system has failed entirely and we coded it wrong. More likely than the last sentence, it wi

The campaign doc is of course updated after all of this succeeds, but in a manner that accepts CAS failure as well. I was tempted to write "if we are ok with CAS failure, then we should just use LCB_SET. but then we may have overwritten a FUTURE slot purchase and brought it back in time (unlikely, BUT POSSIBLE if network congestion)", therefore I do need to CAS input for the campaign doc (but remember, stop trying after first try fails (unless it's an error we should retry. stop only after first CAS fail)).

The 10 in the second sentence represents "number of nodes", and we do that random number genration once per second... thus giving us to (if we desire) cryptographically secure "distribution" amongst the 10. It doesn't matter if the number 0 isn't chosen and one second slips by where

Actually it makes more sense for them to all agree an an alternating schedule (it makes the software more scalable IN THE FUTURE (won't be evident just yet) to use cryptographic level-distribution for a pre-arranged alternating schedule that all participators agreed on. "Append" might be a helpful tool in keeping track of the schedule and participants, but i've just opened a whole can of worms with that design (simple but need to wrap my head around it completely i can tell (so, simple... just not yet ;-P). To KISS I can use the easy-shifting-by-ten planning, but try to make the planning part of it modular somehow.

It is not a big deal if no nodes are chosen randomly (though we can guarantee it using a schedule) if we just use a simple-UNCOORDINATED (yet still cryptographically distributed if we desire (YESSS THIS IS BEST WAY FUCK COORDINATING)). sha1("'rand()' + 'currentTimeString' + 'per-node-id'") and then sharding as much as needed (10 is easy) would give me good results. I'll try to say for the third time: if all 10 (n) nodes get lucky and choose to do the recovery process all at the same second by sheer chance, the system STILL functions fine and dandy. They can and need to all be able to do it together, perhaps by dumb luck a different machine doing each stage working fine too (knowing when a CAS fail is ok).


There is a way to scale what I have just described for a single "campaign" (series of slots (most important doc of which is the slot (which gets filled via LCB_ADD (after locking/declaring the buy in his user account))) to generic key usage, and in that way of looking at it where you have tons of them like that, it is effectively "journaling". In fact what you have just designed IS journaling. It is your system finally perfected. I fucking knew just hacking at it and meditating I'd perfect it. Ok actually I didn't but it doesn't surprise me.


If the user account is locked when we log in and the slot they wanted to buy is not theres, we recover by unlocking the account without debiting (cas may fail as user could be logged in somewhere else and doing just fine). We do not ever proceed forward with the buy when we detect at login that the user-account is locked. It is assumed that the "rand % 10 == 0" recovery 'possy'" will do that, but they will only do it if a given Wt machine (the one they are logged into) does the user-account-lock AND the slot fill at the immediate behest of the user. Getting only the user account doc and seeing it being locked on login, we _DO_ do a check for the slot he intended to fill, but if it's empty then we go into 1sec polling of the slot which is declared to be bought. We don't know who is going to win (BUT WE ARE INTERESTED) but we stay out of it because the user did not initiate it explicitly in this session (however if they do (would be AGAIN if thinking cross-session), then yea we go for it. We are interested in who is going to win because IF IT ISN'T US THAT ENDS UP WINNING, _WE_ are now responsible for cas-unlocking (can fail because neighbor 'login-recoveries' could be doing same process and just beat us, but doing it via cas is still crucial (like above)) the user-account [without debiting]. If as we monitor it we see that we did win, we back off / forget and don't do shit because the "rand % 10" possy will take care of the user-account-unlocking


Even though the "rand() % 10" possy gives us near-100% probability that at least one of the 10 will be chosen to perform "probably not needed tons of false positives but gives us one second max recovery time guarantee AND is not very expensive at all so totally worth it recovery check/test/fix", we can do a "10 second max" lazy verification test. Remember that individual users 'getting' that campaign document are going to be what's driving this stuff (the 100ms max get-and-subscribe-polling (single mutex per wt grabbing when specific WApplication does the poll when detecting 100ms has elapsed), AND the 1-second ON AVERAGE (no guarantee) mostly-false-positive slot[n+1] recovery check/test/fix)... we only use get-and-subscribe-polling for really popular docs that EASILY make 1 user per 100ms (although 'viewing page' still counts for the subscription of course (if the wapplication session is alive), so actually we don't use GET requests but set a fucking 100ms timer... oh shit easy..). ANYWAYS, even though we will TRY to get the slot[n+1] almost every second, each machine should still do a "10 sec max" rule that then does it regarless of the rand() % 10 result. Getting to that code path would be ridiculously rare and probably indicative of a shitty rng.


the "10" mentioned above it is hacked in, but can be made dynamic: DON'T make it dynamic [yet], because the project to do that is way beyond the scope of Abc. Even though it is a very interesting and worthwhile project TODOreq (<- not an ABC TODOreq), it would take wwaaaaay the fuck too long. It's a synchronization problem you should NOT deal with pre-ABC-launch. Having 10 hardcoded like that and just 'knowing' that 10 is also the node count actually saves you a shit ton of effort/code/logic/tevs... and of course 10 can be hooked up to a simple slider GUI that is hooked up to a 1-hour cron job to detect node count via coucbase's admin REST api (oops i just solved it :-P, EXCEPT that the solution doesn't failover (ok do 2+ of them, done))


If when one of the "rand() % 10" possy sees a slot filled, he should wait another 100ms to see if the campaign doc gets updated to reflect it: the "probably NOT failing" driving node may just need more time to finish. However, on the flip side of things, weird circumstances could mean that the recovery possy does ALL of the transaction-making/user-account-unlocking-debitting/campaign-updating because the above 100ms of extra time isn't enough (network congestion: it is a race condition but still worth taking into account). So the "probably NOT failing" driving node (the one whose sole responsibility is to do the "user-account-lock" and "slot-fill" back-to-back in order to do a purchase (but as mentioned, we can fail safely if only user-account-lock (rolls back, never forward (TODOoptimization: on login we can prompt continuation (fuck that for now)) is done), once it completes the user-account-lock && slot-fill, BECOMES effectively a member of the recovery possy. It proceeds with the "finishing up of the transaction" (which any of the "rand() % 10" could also do) right away (it is who will do it most 99.999% of the time), _AND_ it does so using the weird-to-understand-why-at-first "CAS-swap-accepting-first-fail" method just like the "rand() % 10" possy does (that is what I meant by it essentially being one of them after the user-account-lock+slot-fill). The reason even the driving node does CAS-swap-accepting-first-fail of the finishing up of the transaction is for the rare race condition mentioned on the first sentence of this paragraph: one of the "rand() % 10" possy, even after waiting 100ms, could have done it first.


It seems weird at a glance that ALL of the wt nodes (subscribers (accounting for 1 or more end-users)) are doing 100ms checks on the campaign doc all the time. That is not a requirement of the design, it is a lazy hack that can be removed. 100ms is, in the lazy hack, the "max" (not accounting for httpd failure ofc) lag that a slot fill (purchase) shows up (and is then subsequently Post'd to all end-users). A more proper solution would be to use rpc or something to to event driven notification instead of 100ms polling. The 100ms polling is used in SUCCESS cases, whereas the 1 second 'on average' (rand() % 10) is VITAL CORE RECOVERY and cannot be outright removed like that. It is still performed by the same nodes doing the 100ms polling [for successful updates], but it is done more relaxedly because failure cases are not that frequent. When I look at it from a top down perspective, I confuse myself on why I'm polling a key (campaign doc) every 100ms by EVERY node and then polling a related node (campaign doc's "lastPurchase"+1) every 1 second on average. The 100ms polling and the 1sec on average polls are for two entirely different purposes: the 100ms polling is to reduce load to the MOST REQUESTED DOC IN THE CLUSTER (all '10' nodes doing a get every 100ms is waaaaaay cheaper than all 10k end-users doing a get every second (and in fact, they wouldn't --- so the 100ms polling is also a hacky solution for updating "users 'subscribed' to the key"). The 1sec timeout thing is completely different: it is my recovery mechanism so that the cluster is never in a fucked state (mid transaction) for more than 1 sec [on average]. I'm starting to think that I shouldn't associate the 100ms 'subscribers' with who does the "rand() % 10" recovery possy shit. I'm starting to think that all nodes, regardless of subscribers, should do recovery possy'ing. BUT in my own specific use case, it turns out that the end effect will [most likely] be the same and all of them will be participating (because campaign doc will for sure (as sure as the "most likely" just mentioned) be the most requested doc). I'm not sure whether splitting the two things apart or keeping them together is more "KISS"... and wouldn't be surprised if both designs are equally complex (in that case, split them).

My brain keeps trying to get ahead of itself trying to genericize how what I've just created is really a full fledged journaling system, BUT I keep punching it back into context because I can't afford to optimize leik dat rite nao. I am quite certain that once I have it completed specific to this use case, analyzing it afterwards I'll just be like "lol" and change some variable NAMES around and be like "well that was easy". Still I keep wondering what the slot[n+1] is called in the generic journaling version and it's tickling my nerd/curiosity xD. STAWP MAYNG DAT TICKLES TEE HEE, FOCUS ON THE PROBLEM AT HAND IT WILL COME TO YOU.


Login recovery (seeing account locked) should also be cas-swap-accepting fail (ONCE we see transaction doc (it may not appear, so we poll for it every 100ms or so to appear)). If the transaction doc appears (or is already there) and it is the one we are locked-pointing-to, we don't do jack diddedly shit. If the transaction doc appears (or is already there) and it tells us that we did not get the slot, we then cas-swap-accepting-fail unlock the user-account (no debit). The entire purpose of this paragraph is to explain why it's 'accepting-fail'. Two (or N) tabs could be open and the user could be trying to login twice, so the two login-recoveries would be competing to do it and it doesn't matter which wins.