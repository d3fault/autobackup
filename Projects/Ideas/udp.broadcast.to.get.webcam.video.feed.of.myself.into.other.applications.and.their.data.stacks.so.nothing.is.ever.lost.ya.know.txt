i could udp broadcast my video feed, but record it before it leaves the network. if this recording fails, i am instantly notified. i can route it to a stable/private-business/stream  and code myself launching errr launch myself coding errr film/record myself coding/launching and so my attempt as a whole is abstracted and if it fails i still have the recording of it, for myself and for others to view. the dht will be highly unstable in the early days and i will film my every interaction with it. i will probably not store private things on it initially... and even ultimately, i want to have air gap security whenever posting something privately. never rely on it entirely. but then i'll always depend on my offline shit. fuck. you can't sync offline shit because then you lose air gap security. what the fuck? it needs to be the case that a decrypted copy of your keys is never unveiled/decrypted on an online computer. all normal online shit needs to be done with an offline airgap. "write only" connections (however) really come in handy here. i think serial is probably hackable. i'll think of something. and it should have instantly verified parity if it needs it. aka lossy write-only connection such as a video feed (do we pay too much for this? what if it's like png format with individual pixels being bits. like qr codes on crack... but sent via analog? can i even do that? hdmi is good enough i think. it's digital. i definitely don't want to send .png video/data(encoded in video) over a network, but doing it in a local connection might actually be mildly bandwidth efficient. i mean an hdmi cable is relatively efficient, ignoring the fact that our process must build the video stream. i might be able to parallelize the .png creation... err, maybe not. but the bitmap creation itself mb. but that might not be worth it... but maybe it is. or maybe i can/should just do bitmap->hdmi actually yea of course you send uncompressed directly to display damn i'm fucking stupid so now i need hdmi capture? then custom code to decode. parallelizing that might be possible too. ensuring the process has adequate processing power during the time the data is read is vital. any data loss due to cpu not being available enough would probably lose more than our parity data can make up for. the parity is there for verification purposes. we probably would rarely use it when the cpu/gpu has enough resources). for this reason i think it might be a good idea to have the decoding process machine be dedicated hardware. it could still be thought of as 'online' since