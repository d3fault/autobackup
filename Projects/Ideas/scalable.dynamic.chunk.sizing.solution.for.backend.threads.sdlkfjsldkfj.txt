Dynamic chunk sizing solution for communicating with backend thread: You pick a maximum response time (10ms?) and code your backend thread object to be able to handle chunks of arbitrary size (and to be able to stop in between chunks). At/near application startup (or functionality init etc), you perform a benchmark. That is, there will be a relatively consistent amount of time for processing N sized chunks of data (as is the case with md5/sha1'ing, for example), so you (using sha1 example) perform as many sha1sums as you can in 10ms and then use that for the block size.

When I say "block size", I mean "unit of work" size. Basically, what is performed in a single SLOT invocation. Even though there will typically be many of "increments" of that SLOT call back to back to back, proper coding makes it so that you can now just call QThread::quit and QThread::wait and will maximally ever only have to wait 10ms (insignificant).

I'm always searching for that nice "threshold" of how often to check for a "quit" (many slot calls, occassional "processEvents" in loops, etc etc -- there are many ways to go about this)... but solution one takes a "top down" (or some fucking direction lol) approach and solves it better/dynamically: by measuring how much we can accomplish on a given CPU under a certain unnoticeable-to-human-but-LOTS-for-a-CPU-unit-of-work amount of time (<-- has to be chosen by a human, but only ever once!).

The beauty of the formula is that, so long as the processing of chunk length is [RELATIVELY (video [de/en]coding isn't perfectly consistent, but is close enough!)] consistent from chunk to chunk (there are a lot of use cases for this!), it scales as hardware performance improves over the years.