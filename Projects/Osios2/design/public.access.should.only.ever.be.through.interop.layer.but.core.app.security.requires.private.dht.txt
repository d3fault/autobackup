The public "module", or even variant (which still can read the same timeline node binaries, so they'd share a lib), should work independently of the "3 full copies". It makes it's own full copy, since it will be on a publicly accessable server, we don't trust the copy to not get deleted by h4x0rz (and we care little when it does happen). The public variant should use libtorrent to distribute "profile chunks". The GUI can look more or less the same (read-only mode though? "replay" ("copycat") only mode I mean?). I don't want to support insertion, though perhaps I can seemlessly transition between "copycat"/replay (when looking at someone else's profile) and "regular". But the level of trust for any public peer is zero, so they would be copycats without the cryptographic verification. ADDITIONALLY/transparently, they could have their own private 2x replica neighbors on LAN.

I feel like I'm reinventing the subnet, but eh with pki instead of derp IPs. I have my own private DHT for backup, it streams in an output-only-safe (vidya-qr?) to the public DHT. Someone can import my public-DHT timeline (profile), and ideally even tangent from it (the tangents are THEIRS, however (if DPL is used ofc), and they could file a pull request but otherwise it does not get re-applied to the originator's timeline stream. I do like github's functionality of showing you branches from your repository (a timeline profile is a repository? I'd say no tbh, a timeline stream represents a single computer session (user), so the timeline stream could contain many things. Creating "projects" and adding to them should basically just be a clever use of the tagging system (TODOreq: all functionality is a clever use of the tagging system (and the tags should remain human readable even though they are parsed). Tags are our abstract entry point into state/state-modification. I'm not 100% sure I can implement this [yet], but pretty sure it's possible))).

The public module is never trusted for anything. Importing anything, even if using qr video, is dangerous and always will be. The only thing I'd be willing to import is qr video that is never parsed, only serialized. Actually this makes no sense because why would I be storing them in the first place? Reason = to be requested later. However, in order to be requested later we have to parse the request (some kind of ID), and parsing ANYTHING from the user is bound to open up security holes. MAYBE if the key were just raw bytes and not read in any fancy way, just good ole' QByteArray data = m_DataByKey.value(key); , and then you check data.isEmpty or however you want to handle misses. MAYBE if you were careful with the keys you could import and handle requests (your response of course needs to be qr-video -- and in such a scenario it that specific box should PROBABLY _ONLY_ import/export those "raw qr video frames". It is a "raw qr video frame" server, and should be only that to limit the amount of security failure points).

Anyways back to the point of the public DHT. Obviously it would be incredibly stupid for all peers to have every timeline node of every peer, so it should use a "subscribe-to-profile" model. PKI should be used I'm thinking, but that doesn't guarantee it's secure. Public DHTs are almost always plagued with security holes the designer didn't consider. Just like the private one can/should when doing HELLO-SYNC, we could leverage libtorrent when the [current] rolling hash we have is determined to be "far" (so the diff is big) away from the [current] rolling hash we want. I'm thinking just a set/constant timeline node count, but really  a set byte size would probably be smarter (each libtorrent peer needs to be able to 'create' the exact matching info-hash from the data they already have (to provide to the swarm(new joiners)). So them all agreeing on a constant byte size solves that (my timeline nodes vary in size, so constant byte size is smarter). Goes without saying that if the diff needed is less than that byte size, the normal HELLO-SYNC procedure would be used and not libtorrent. Libtorrent is simply triggered when the byte size for one of the requests during the HELLO-SYNC phase is greater than or equal to that constant compile time defined byte size. The public DHT could re-use the HELLO-SYNC code, yes, but after that their network protocol is different because there is no cryptographic verification going on (aside from the implicit one done in libtorrent). What I mean is senders don't want or care about (because they wouldn't trust anyways) cryptographic verification from receivers. I do want a push DHT for sure (prioritized, as you can see), but requesting is certainly desired as well (HELLO-SYNC catch up needs it I'm thinking (but maybe not idk yet depends what I choose and I haven't decided yet)).

Speaking of HELLO-SYNC, I realized that in the network protocol, after the HELLO-SYNC (since it's profile agnostic) and right about at "I am profile %profileName%", I should also send the OsiosClientRenderTypeEnum. The 3 potential values are OsiosClientRenderTypeGui, OsiosClientRenderTypeCli, and OsiosClientRenderTypeWeb. I could maybe introduce a "DontRender" one that only uses cryptographic verification, but so long as I can render a QWidget to a PNG when X isn't running (*goes and tests this momentarily*), I'm leaning towards requring OsiosClient be required to implement rendering -- since it is a core part of the applicatin's functionality.

The OsiosClientRenderTypeEnum needs to be sent because the receiver of your timeline nodes needs to know what kind of snapshot(rendering of widget to QImage in GUI case) to generate. But, like the profileName, it only should be sent once up front (that enum can be sent with each and every timeline node FOR NOW, just like the profile name, but it's a huge TODOoptimization to get profile name and that enum out of each action overhead)

Damnit "cannot connect to X server". I might be able to start X server without starting X client and then be able to render, but idfk. That's kinda hacky anyways... maybe I should just support GUI only for now?